<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Lecture 4</title>
<meta name="author" content="(Adolfo De Unánue)"/>

<link rel="stylesheet" href="http://cdn.jsdelivr.net/reveal.js/2.5.0/css/reveal.css"/>
<link rel="stylesheet" href="http://cdn.jsdelivr.net/reveal.js/2.5.0/css/theme/night.css" id="theme"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'http://cdn.jsdelivr.net/reveal.js/2.5.0/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<meta name="description" content="Big data - Lecture 6.">
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<h1>Lecture 4</h1>
<h2>Adolfo De Unánue</h2>
<h2><a href="mailto:adolfo.deunanue@itam.mx">adolfo.deunanue@itam.mx</a></h2>
<h2></h2>
</section>

<section>
<section id="slide-sec-1">
<h2 id="sec-1">Docker</h2>
<div class="outline-text-2" id="text-1">
</div></section>
<section id="slide-sec-1-1">
<h3 id="sec-1-1">Obtener la imagen</h3>
<pre class="example">
docker pull nanounanue/docker-hadoop
</pre>

</section>
<section id="slide-sec-1-2">
<h3 id="sec-1-2">Ejecutar un contenedor</h3>
<pre class="example">
docker run -ti --rm \
  -e "AUTHORIZED_SSH_PUBLIC_KEY=$(cat ~/.ssh/id_rsa.pub)" \
  -v /home/nano/tmp/docker-hadoop-data/:/home/hduser/hdfs-data/ \
  -v /home/nano/tmp/docker-hadoop-logs/:/srv/hadoop/logs/ \
  -p 2122:2122 -p 2181:2181 -p 39534:39534 -p 9000:9000 \
  -p 50070:50070 -p 50010:50010 -p 50020:50020 -p 50075:50075 \
  -p 50090:50090 -p 8030:8030 -p 8031:8031 -p 8032:8032 \
  -p 8033:8033 -p 8088:8088 -p 8040:8040 -p 8042:8042 \
  -p 13562:13562 -p 47784:47784 -p 10020:10020 -p 19888:19888 \
nanounanue/docker-hadoop /bin/bash
</pre>

</section>
<section id="slide-sec-1-3">
<h3 id="sec-1-3">Contenedor con Hadoop</h3>
<pre class="example">
docker run -ti --name hadoop_pseudodistribuido \
  -e "AUTHORIZED_SSH_PUBLIC_KEY=$(cat ~/.ssh/id_rsa.pub)" \
  -v /home/nano/tmp/docker-hadoop-data/:/home/hduser/hdfs-data/ \
  -v /home/nano/tmp/docker-hadoop-logs/:/srv/hadoop/logs/ \
  -p 2122:2122 -p 2181:2181 -p 39534:39534 -p 9000:9000 \
  -p 50070:50070 -p 50010:50010 -p 50020:50020 -p 50075:50075 \
  -p 50090:50090 -p 8030:8030 -p 8031:8031 -p 8032:8032 \
  -p 8033:8033 -p 8088:8088 -p 8040:8040 -p 8042:8042 \
  -p 13562:13562 -p 47784:47784 -p 10020:10020 -p 19888:19888 \
nanounanue/docker-hadoop
</pre>

</section>
<section id="slide-sec-1-4">
<h3 id="sec-1-4">Conectarse al contenedor</h3>
<pre class="example">
ssh hduser@localhost -p 2122
</pre>

</section>
<section id="slide-sec-1-5">
<h3 id="sec-1-5">Navegador Web</h3>
<ul>
<li><a href="http://127.0.0.1:50090">Consola de Yarn</a></li>

<li><a href="http://127.0.0.1:50070">Consola de HDFS</a></li>

</ul>


</section>
</section>
<section>
<section id="slide-sec-2">
<h2 id="sec-2">Apache Hadoop</h2>
<div class="outline-text-2" id="text-2">
</div></section>
<section id="slide-sec-2-1">
<h3 id="sec-2-1">¿Por qué?</h3>
<ul>
<li>Aunque la capacidad de los discos ha aumentado considerablemente, la velocidad de los mismos no lo ha hecho igual.
<ul>
<li>Los discos actuales de <code>1 Tb</code>, tardan en leerse completos a <code>100 Mb/s</code> cerca de dos a tres horas.</li>
<li>Podemos <i>paralelizar</i> las fuentes en varios discos.
<ul>
<li>Para leerla simultáneamente</li>

</ul></li>
<li>Con varios discos, la <b><b>probabilidad de falla</b></b> aumenta.</li>

</ul></li>
<li>Otro problema es la distribución ¿Cómo combinas varios <code>file systems</code>?</li>

</ul>

</section>
<section id="slide-sec-2-2">
<h3 id="sec-2-2">¿Qué es?</h3>
<ul>
<li>Sistema confiable (<i>realiable</i>) de almacenamiento compartido y de análisis.
<ul>
<li><b>Almacenamiento</b>: HDFS</li>
<li><b>Análisis</b>: MapReduce</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-2-3">
<h3 id="sec-2-3">¿Cómo?</h3>
<ul>
<li><code>MapReduce</code> es un sistema de procesamiento <i>batch</i>
<ul>
<li>Permite correr <i>queries</i> contra <b><b>toda</b></b> tu base de datos</li>
<li>Pero el resultado puede tardar minutos, horas, etc&#x2026;</li>
<li>No permite tener a un humano sentado ahí para retroalimentar.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-2-4">
<h3 id="sec-2-4">¿Cómo?</h3>
<ul>
<li>Ahora, gracias a <code>YARN</code> (ver más adelante) tenemos diferentes tipos de procesamiento:
<ul>
<li><i>SQL Interactivo</i>: <code>Impala</code>, <code>Hive</code>, <code>Tez</code>.</li>
<li><i>Iterativos</i>: <code>Spark</code>.</li>
<li><i>Procesamiento de flujos</i>: <code>Storm</code>, <code>Spark Streaming</code>.</li>
<li><i>Búsquedas</i>: <code>Solr</code>.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-2-5">
<h3 id="sec-2-5">¿Por qué no otros sistemas?</h3>
<ul>
<li>¿Por qué no usar un <code>PostgreSQL</code> con muchos discos, muy <i>pimpeado</i>?
<ul>
<li>El problema viene del tiempo que toma mover la cabeza del disco a otro lugar del disco para leer o escribir datos (<i>seek time</i>).
<ul>
<li>¿Cuál es la <i>latencia</i> de la operación?</li>

</ul></li>

</ul></li>

<li>¿Por qué no <i>Grid</i>?
<ul>
<li>Por ejemplo, cosas  de <code>HPC</code> que usan <code>MPI</code>.
<ul>
<li>Son intensivos en <b><b>CPU</b></b>.</li>

</ul></li>
<li>Pero si hay que mover cientos de gigabytes, la transferencia de datos se vuelve un problema.
<ul>
<li>Basicamente, en que <code>Hadoop</code> opera con <i>data locality</i>.</li>

</ul></li>

</ul></li>

</ul>

</section>
<section id="slide-sec-2-6">
<h3 id="sec-2-6">Componentes de Apache Hadoop</h3>
<ul>
<li><b>MapReduce</b> Modelo de procesamiento <i>batch</i> de datos distribuido y paralelo.</li>
<li><b>HDFS</b> Sistema de archivos (<i>file system</i>) distribuido.</li>
<li><b>Pig</b> Capa de abstracción encima de <code>MapReduce</code>. Utiliza <i>Pig Latin</i> un lenguaje de flujo de datos
<ul>
<li>Como <code>dplyr</code></li>

</ul></li>
<li><b>Hive</b> (Hadoop InteractiVE) Es un lenguaje parecido al <code>SQL</code>: <code>HQL</code>, para ejecutar <i>queries</i> sobre el <code>HDFS</code>.</li>
<li><b>HBase</b> Base de datos distribuida orientada a columnas.
<ul>
<li>Depende de <code>Zookeeper</code>.</li>

</ul></li>

</ul>


</section>
<section id="slide-sec-2-7">
<h3 id="sec-2-7">Componentes de Apache Hadoop</h3>
<ul>
<li><b>Zookeeper</b> Sistema distribuido de coordinación.</li>
<li><b>Sqoop</b> Herramienta para mover datos entre <code>RDBM</code> y <code>HDFS</code>.</li>
<li><b>Flume</b> Servicio para recolectar, agregar y mover grandes cantidades de datos entre máquinas individuales y el <code>HDFS</code>.</li>
<li><b>Oozie</b> Sistema de <i>workflow</i>, se usa para coordinar varios <i>jobs</i> de <b>MapReduce</b>.</li>
<li><b>Mahout</b> Biblioteca de <i>Machine Learning</i>.
<ul>
<li>Ver la carpeta <code>docs</code>.</li>

</ul></li>
<li><b>Ambari</b> Simplifica el aprovisionamiento, gestión y <i>monitoreo</i> de un <i>cluster</i> de Hadoop.</li>
<li><b>Avro</b> Formato de serialización y de persistencia de datos.</li>
<li>Entre otros&#x2026;</li>

</ul>



</section>
</section>
<section>
<section id="slide-sec-3">
<h2 id="sec-3">HDFS : Hadoop File System</h2>
<div class="outline-text-2" id="text-3">
</div></section>
<section id="slide-sec-3-1">
<h3 id="sec-3-1">HDFS</h3>
<ul>
<li>Sistema de almacenamiento distribuido.
<ul>
<li><i>Namenode</i> <code>-&gt;</code> Master</li>
<li><i>Datanode</i> <code>-&gt;</code>  Slaves</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-3-2">
<h3 id="sec-3-2">Ventajas</h3>
<ul>
<li>Archivos muy grandes</li>
<li><i>write once, read many times</i>.</li>
<li>Hardware <span class="underline">normal</span></li>

</ul>

</section>
<section id="slide-sec-3-3">
<h3 id="sec-3-3">Desventajas</h3>
<ul>
<li>Acceso a los datos de baja latencia.</li>
<li>Muchos archivos pequeños.</li>
<li>Muchas escrituras, modificaciones</li>

</ul>

</section>
<section id="slide-sec-3-4">
<h3 id="sec-3-4">Tamaño del bloque</h3>
<ul>
<li>Cada <i>file system</i> define un tamaño de bloque, el cual es la cantidad mínima de datos que puede escribir o leer.
<ul>
<li>Típicamente son de <code>kb</code>.</li>

</ul></li>
<li>En <code>HDFS</code>, el bloque es de <code>128 Mb</code> por <i>default</i>.
<ul>
<li>Es el concepto fundamental, no el archivo.</li>

</ul></li>

</ul>


</section>
<section id="slide-sec-3-5">
<h3 id="sec-3-5"><i>Namenode</i></h3>
<ul>
<li>Gestiona el <i>filesystem</i>
<ul>
<li>Mantiene el árbol del <i>filesystem</i>.</li>
<li>Mantiene los <code>metadatos</code> de todos los archivos y carpetas del árbol.</li>
<li>Esta información se guarda en disco en dos archivos:
<ul>
<li><code>namespace image</code></li>
<li><code>edit log</code></li>

</ul></li>

</ul></li>
<li>Indica a los <i>datanodes</i> realizar tareas de bajo nivel de <code>I/O</code>.</li>
<li><i>Book Keeper</i>
<ul>
<li>División de archivos en bloques (¿Cómo?)</li>
<li>En qué <i>datanode</i> (¿Quién?)</li>
<li>Monitorea.</li>

</ul></li>
<li>Uso intensivo de <code>RAM</code> y de <code>I/O</code>.</li>
<li>Si se <i>cae</i> el <code>HDFS</code> no puede ser usado
<ul>
<li>Hasta la versión <code>1.x</code> el <i>single point of failure</i>, en Hadoop 2 se incorporó la característica de <i>HIgh Availability</i>.</li>
<li>Su caída puede causar la pérdida total de los datos.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-3-6">
<h3 id="sec-3-6"><i>Namenode</i></h3>
<ul>
<li>Hadoop proveé de dos formas de aliviar esta situación:
<ul>
<li>Respaldos: Se puede configurar al <i>namenode</i> para que escriba su estado a varios <i>filesystems</i>.</li>
<li><i>Secondary Namenode</i></li>

</ul></li>

</ul>

</section>
<section id="slide-sec-3-7">
<h3 id="sec-3-7"><i>Namenode</i></h3>

<div class="figure">
<p><img src="./imagenes/Selección_004.png" alt="Selección_004.png" />
</p>
</div>


</section>
<section id="slide-sec-3-8">
<h3 id="sec-3-8"><i>Datanode</i></h3>
<ul>
<li>Lee y escribe los <code>HDFS</code> <i>blocks</i> y los convierte en archivos del <b>FS</b> local.</li>
<li>Se comunica con otros <i>datanodes</i> para la replicación de los datos.</li>
<li>Pueden realizar <i>caching</i> de bloques.</li>

</ul>

</section>
<section id="slide-sec-3-9">
<h3 id="sec-3-9"><i>Datanode</i></h3>

<div class="figure">
<p><img src="./imagenes/Selección_005.png" alt="Selección_005.png" />
</p>
</div>

</section>
<section id="slide-sec-3-10">
<h3 id="sec-3-10"><i>Secondary Name Node</i></h3>
<ul>
<li>Como el <i>namenode</i> sólo hay uno por <i>cluster</i>.</li>
<li>No es un <i>namenode</i>.</li>
<li>Evita que el <code>edit log</code> crezca mucho.</li>
<li>No recibe ni guarda cambios en tiempo real del <code>HDFS</code>.
<ul>
<li>Va atrás del <i>namenode</i>.</li>

</ul></li>
<li>Sólo toma <i>snapshots</i> de la metadata.</li>

</ul>


</section>
<section id="slide-sec-3-11">
<h3 id="sec-3-11">Línea de comandos</h3>
<ul>
<li>Hay muchas maneras de conectarse y usar el <code>HDFS</code>. La línea de comandos es una de ellas.
<ul>
<li>Y espero que ya sepan que es de las más útiles y eficientes.</li>

</ul></li>

<li>Ayuda: <code>hadoop fs -help</code></li>

</ul>

</section>
<section id="slide-sec-3-12">
<h3 id="sec-3-12">Línea de comandos</h3>
<pre class="example">
hadoop fs -cmd &lt;args&gt;
hadoop fs -ls
hadoop fs -mkdir
hadoop fs -copyFromLocal
hadoop fs -copyToLocal
hadoop fs -put archivo archivo_hdfs
hadoop fs -get archivo_hdfs
hadoop fs -cat archivo_hdfs
hadoop fs -cat archivo_hdfs head
hadoop fs -tail archivo_hdfs
hadoop fs -rm archivo_hdfs
</pre>

</section>
<section id="slide-sec-3-13">
<h3 id="sec-3-13">Copia en paralelo</h3>
<pre class="example">
hadoop distcp
</pre>

</section>
<section id="slide-sec-3-14">
<h3 id="sec-3-14">Modo Pseudodistribuido</h3>
<ul>
<li>Crea una imagen sin Hadoop corriendo, vamos a explicar que significa <i>pseudodistribuido</i>.</li>

</ul>

</section>
<section id="slide-sec-3-15">
<h3 id="sec-3-15">Ejercicio</h3>
<ul>
<li>Crea una imagen con Hadoop corriendo.</li>
<li>Conéctate con el usuario <code>hduser</code>.</li>
<li>Verifique que <code>alias</code> tiene definido el usuario <code>hduser</code>.
<ul>
<li>Usa el comando <code>alias</code>.</li>

</ul></li>
<li>Crear una carpeta <code>ufo</code> en el <code>HDFS</code> y suba  los archivos de <code>ufo</code> a la carpeta recién creada.
<ul>
<li>Descomprime los archivos antes de subirlos</li>
<li>Crea un <i>script</i> para esta tarea, llámalo <code>ufo_hdfs.sh</code>.</li>

</ul></li>
<li>Crear una carpeta <code>gdelt</code> en el <code>HDFS</code> y suba los archivos de <code>gdelt</code> a esta carpeta.
<ul>
<li>Descomprime los archivos antes de subirlos</li>
<li>Crea un <i>script</i> para esta tarea, llámalo <code>gdelt_hdfs.sh</code>.</li>

</ul></li>
<li>Muestra las carpetas en la línea de comandos.
<ul>
<li>Modifica los usuarios y permisos del HDFS ¿Cómo crees que se haga?</li>

</ul></li>
<li>Muestra las carpetas en la vista web.</li>

</ul>

</section>
</section>
<section>
<section id="slide-sec-4">
<h2 id="sec-4">MapReduce</h2>
<div class="outline-text-2" id="text-4">
</div></section>
<section id="slide-sec-4-1">
<h3 id="sec-4-1">MapReduce en Hadoop</h3>
<ul>
<li>Principal <i>framework</i> de ejecución de <code>Apache Hadoop</code>.</li>
<li>Inspirado en las operaciones <b>MAP</b> y <b>REDUCE</b> de los lenguajes funcionales.</li>
<li>Modelo de programación para proceso de datos distribuido  y paralelo.</li>
<li>Divide las tareas (<i>jobs</i>) en fases de <i>mapeo</i> y fases de <i>reducción</i>.</li>
<li>Los desarrolladores crean tareas <i>MapReduce</i> para Hadoop usando datos guardados en el <code>HDFS</code>.</li>

</ul>

</section>
<section id="slide-sec-4-2">
<h3 id="sec-4-2">MapReduce: Ventajas</h3>
<ul>
<li><i>Fault-tolerant</i>.</li>
<li>Esconde los detalles de implementación a los programadores.</li>
<li>Escala con el tamaño de los datos.</li>

</ul>


</section>
<section id="slide-sec-4-3">
<h3 id="sec-4-3">MapReduce</h3>
<ul>
<li>Dos fases de procesamiento:
<ul>
<li><i>key-value</i> como Input y Output</li>
<li>El programador especifica:
<ul>
<li>Tipos de <i>key-value</i></li>
<li>Funciones: <code>MAP</code> y <code>REDUCE</code>.</li>

</ul></li>

</ul></li>

</ul>


</section>
<section id="slide-sec-4-4">
<h3 id="sec-4-4">Una pequeña regresión&#x2026;</h3>

</section>
<section id="slide-sec-4-5">
<h3 id="sec-4-5">map-reduce: Matemáticamente</h3>
<pre class="example">
map: (k1, v1) -&gt; list(k2, v2)
</pre>

<ul>
<li><code>map</code> Mapea (aplica una función <i>f</i>) un conjunto de entrada de pares <i>key-value</i> a otro conjunto intermedio de <i>key-values</i></li>

</ul>


</section>
<section id="slide-sec-4-6">
<h3 id="sec-4-6">map-reduce: Matemáticamente</h3>
<pre class="example">
reduce: (k2, list(v2)) -&gt; list(k3, v3)
</pre>

<ul>
<li><code>reduce</code>  Aplica una función <i>g</i> a todos los valores (<i>values</i>) asociados a una llave (<i>key</i>) y acumula el resultado. Emite pares de <i>key-values</i>.</li>

</ul>

</section>
<section id="slide-sec-4-7">
<h3 id="sec-4-7">Python <code>map</code></h3>
<div class="org-src-container">

<pre  class="src src-python"># Equivalente en for-loop

items = [1,2,3,4,5]
cuadrados = []
for x in items:
    cuadrados.append(x**2)

print cuadrados
</pre>
</div>


<div class="org-src-container">

<pre  class="src src-python"># Usando la funcion map(function, sequence)

items = [1,2,3,4,5]

print list(map((lambda x: x**2), items))
</pre>
</div>


</section>
<section id="slide-sec-4-8">
<h3 id="sec-4-8">Python <code>reduce</code></h3>
<div class="org-src-container">

<pre  class="src src-python"># Equivalente en for-loop
L = [1,2,3,4]
result = L[0]
for x in L[1:]:
    result = result*x

print result
</pre>
</div>

<div class="org-src-container">

<pre  class="src src-python"># Usando la funcion reduce(funcion, secuencia)
print reduce((lambda x,y: x*y), [1,2,3,4])
</pre>
</div>

</section>
<section id="slide-sec-4-9">
<h3 id="sec-4-9">Python <code>map</code> y <code>reduce</code></h3>
<div class="org-src-container">

<pre  class="src src-python">a = range(1, 4)
b = range(4, 9)
c = range(9, 15)
print "a -&gt;  %s, b -&gt; %s , c -&gt; %s" % (a, b, c)

L1 = map(lambda x:len(x), [a,b,c])
print "L1 -&gt; %s" % L1

L2 = reduce(lambda x, y: x+y, L1)
print "L2 -&gt; %s" % L2
</pre>
</div>



</section>
<section id="slide-sec-4-10">
<h3 id="sec-4-10">MapReduce y map-reduce</h3>
<ul>
<li>Básicamente es lo mismo, pero&#x2026;</li>
<li><code>map</code>, <code>reduce</code> (entre otras) son parte de lenguajes funcionales.</li>
<li><code>MapReduce</code> es la aplicación de esta idea aplicada a problemas <i>vergonzosamente</i> <i>paralelos</i>.
<ul>
<li>Ver la carpeta <code>docs</code> para el artículo de <b>Google</b> sobre <code>MapReduce</code>.</li>

</ul></li>

</ul>


</section>
<section id="slide-sec-4-11">
<h3 id="sec-4-11">GNU Parallel</h3>
<div class="org-src-container">

<pre  class="src src-sh">find ./data/books -type f | parallel -j0 egrep -i  '\[\[:digit:\]\]' {} | awk '{s+=$1} END {print s}'
</pre>
</div>


<ul>
<li><b>¿Puedes identificar las partes <code>map</code> y <code>reduce</code>?</b></li>
<li>Esto ya es un <code>MapReduce</code>.</li>

</ul>


</section>
<section id="slide-sec-4-12">
<h3 id="sec-4-12">MapReduce en Hadoop</h3>
<ul>
<li>A nivel programático:
<ul>
<li><i>Data</i> de entrada</li>
<li>Programa MapReduce</li>
<li>Configuración</li>
<li>Subtareas: <code>map</code> y <code>reduce</code></li>

</ul></li>

</ul>


</section>
<section id="slide-sec-4-13">
<h3 id="sec-4-13">MapReduce: <i>Mapper</i></h3>
<ul>
<li>Hadoop divide la entrade de datos al <i>job</i> MapReduce en pedazos de tamaño fijo llamados <i>input splits</i>.</li>
<li>Hadoop crea una tarea <code>map</code> para cada <i>input split</i>.</li>
<li><code>map</code> escribe al <i>file system</i> local.
<ul>
<li>Si el <code>reducer</code> tiene éxito se borra la salida del <i>mapper</i>.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-4-14">
<h3 id="sec-4-14">Map only</h3>

<div class="figure">
<p><img src="./imagenes/map_only.png" alt="map_only.png" />
</p>
</div>


</section>
<section id="slide-sec-4-15">
<h3 id="sec-4-15">MapReduce: <i>Reducer</i></h3>
<ul>
<li>La entrada es la salida de (posiblemente) todos los <i>mappers</i>.</li>
<li>Estas se transmiten vía red al nodo donde corre el <i>reducer</i>.</li>
<li>La salida se guarda en el <code>HDFS</code>.</li>

</ul>

</section>
<section id="slide-sec-4-16">
<h3 id="sec-4-16">Map, One reduce</h3>

<div class="figure">
<p><img src="./imagenes/map_one_reduce.png" alt="map_one_reduce.png" />
</p>
</div>

</section>
<section id="slide-sec-4-17">
<h3 id="sec-4-17">MapReduce</h3>

<div class="figure">
<p><img src="./imagenes/map_reduce.png" alt="map_reduce.png" />
</p>
</div>


</section>
<section id="slide-sec-4-18">
<h3 id="sec-4-18">MapReduce: <i>Combiner</i></h3>
<ul>
<li>Es una medida de optimización.</li>
<li>Es para ahorrar ancho de banda.</li>
<li>Una especie de <i>reducer</i> local.</li>
<li>No es parte (estrictamente) del MapReduce
<ul>
<li>Por eso no lo había mencionado.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-4-19">
<h3 id="sec-4-19">MapReduce: Componentes</h3>
<p>
<i>Job Tracker</i>
</p>

<ul>
<li>Uno por <i>cluster</i>.</li>
<li>Contacto entre Hadoop y la aplicación cliente.</li>
<li>Determina el plan de ejecución:
<ul>
<li>¿Qué archivos?</li>
<li>¿Quién hace las tareas?</li>
<li>Monitoriza.</li>

</ul></li>
<li>Si una tarea falla, relanza la tarea.</li>

</ul>

</section>
<section id="slide-sec-4-20">
<h3 id="sec-4-20">MapReduce: Componentes</h3>
<p>
<i>Task tracker</i>
</p>

<ul>
<li>Esclavo</li>
<li>Ejecuta la tarea en cada nodo</li>
<li>Uno por nodo
<ul>
<li>Pero se pueden crear varios <i>Java Virtual Machines</i> (JVM) para tener varios <i>Mappers</i> o <i>Reducers</i> en paralelo.</li>

</ul></li>
<li><code>PING</code> al <i>JobTracker</i>, si no, se supone que el nodo a muerto.</li>

</ul>


</section>
<section id="slide-sec-4-21">
<h3 id="sec-4-21">Arquitectura: MapReduce</h3>

<div class="figure">
<p><img src="./imagenes/arquitectura_MR.png" alt="arquitectura_MR.png" />
</p>
</div>



</section>
</section>
<section>
<section id="slide-sec-5">
<h2 id="sec-5">Apache Haoop 2.x: YARN</h2>
<div class="outline-text-2" id="text-5">
</div></section>
<section id="slide-sec-5-1">
<h3 id="sec-5-1">YARN</h3>
<ul>
<li>La infraestructura de Hadoop <code>0.x</code> y <code>1.x</code> era monolítica, por eso fue rediseñada.</li>
<li><code>YARN</code>: <i>Yet Another Resource Negotiator</i>.</li>
<li>La gestión de recursos es extraída de los paquetes de <code>MapReduce</code> para que puedan ser utilizadas por otros componentes.</li>
<li>Aportaciones
<ul>
<li>Escalabilidad.</li>
<li>Compatibilidad con <code>MapReduce</code>.</li>
<li>Mejoras en la gestión del <i>cluster</i>.</li>
<li>Soporte para otros modelos de programación (además de <code>MapReduce</code>).
<ul>
<li><i>Graph processing</i></li>
<li><i>Message Passing Interface</i> (<b>MPI</b>).</li>
<li>Soporte para procesamiento <i>real-time</i> o <i>near real-time</i>.
<ul>
<li><code>MapReduce</code> es <i>batch-oriented</i>.</li>

</ul></li>

</ul></li>
<li>Agilidad.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-5-2">
<h3 id="sec-5-2">YARN</h3>
<ul>
<li>Se dividieron las dos responsabilidades del <i>JobTracker</i>:
<ul>
<li>Gestión de recursos (<i>Resource Management</i>)</li>
<li>Asignación y vigilancia de trabajos (<i>Job scheduling-monitoring</i>)</li>

</ul></li>

<li>La idea es tener un <i>ResourceManager</i> global y un <i>NodeManager</i> por
nodo esclavo, los cuales forman un sistema para la administración de
aplicaciones distribuidas.</li>

<li>El <i>ResourceManager</i> tiene dos componentes principales:
<ul>
<li><i>Scheduler</i>: Asigna los recursos para las aplicaciones (<i>pluggeable</i>).</li>
<li><i>Application Manager</i>: Responsable de aceptar las solicitudes de
trabajos, negociando al principio para ejecutar el <i>Application
Master</i> específico y provee un servicio de reinicio, por si el
<i>Application Master</i> falla.</li>

</ul></li>

<li>En cada nodo:

<ul>
<li>El <i>Application Master</i>: Negocia sus recursos con el <i>Scheduler</i>,</li>

</ul>
<p>
monitorea sus avances y reporta su estatus.
</p>

<ul>
<li>El <i>NodeManager</i> es el responsable de los contenedores,
monitorear el uso de recursos y reportar todo al
<i>ResourceManager</i>.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-5-3">
<h3 id="sec-5-3">Arquitectura MapReduce Hadoop 1.x</h3>

<div class="figure">
<p><img src="./imagenes/MRArch.png" alt="MRArch.png" />
</p>
</div>

</section>
<section id="slide-sec-5-4">
<h3 id="sec-5-4">Arquitectura Hadoop 2.x</h3>

<div class="figure">
<p><img src="./imagenes/Selección_003.png" alt="Selección_003.png" />
</p>
</div>


</section>
<section id="slide-sec-5-5">
<h3 id="sec-5-5">Cambios 1.x -&gt; 2.x</h3>

<div class="figure">
<p><img src="./imagenes/yarn.png" alt="yarn.png" />
</p>
</div>


</section>
<section id="slide-sec-5-6">
<h3 id="sec-5-6">Multiparadigma en Hadoop 2.x</h3>

<div class="figure">
<p><img src="./imagenes/YARN.png" alt="YARN.png" />
</p>
</div>


</section>
</section>
<section>
<section id="slide-sec-6">
<h2 id="sec-6">Hello World!: Word count</h2>
<div class="outline-text-2" id="text-6">
</div></section>
<section id="slide-sec-6-1">
<h3 id="sec-6-1">Word count</h3>
<ul>
<li>Es el ejemplo <i>Hola Mundo</i> de Apache Hadoop.</li>
<li>No sólo eso, es el ejemplo que se utiliza en el trabajo seminal
<ul>
<li><b>MapReduce: Simplified Data Processing on Large Clusters</b> <i>(2006)</i>.</li>
<li>En la carpeta <code>docs</code> como ya había dicho.</li>

</ul></li>
<li>Solamente 1 <code>Map</code> y 1 <code>Reduce</code>.</li>

</ul>


</section>
<section id="slide-sec-6-2">
<h3 id="sec-6-2">Word count</h3>
<ul>
<li><b>mapper</b>
<ul>
<li><code>k1</code> -&gt; nombre de archivo</li>
<li><code>v1</code> -&gt; texto del archivo</li>
<li><code>k2</code> -&gt; palabra</li>
<li><code>v2</code> -&gt; "1"</li>

</ul></li>

<li><b>reducer</b>
<ul>
<li><code>k2</code> -&gt; palabra</li>
<li>list(v2) -&gt; (1,1,1,1,1,1,&#x2026;, 1)</li>

</ul>
<p>
Suma los "1" y produce una lista de
</p>

<ul>
<li>k3 -&gt; palabra</li>
<li>v3 -&gt; suma</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-6-3">
<h3 id="sec-6-3">Word count</h3>

<div class="figure">
<p><img src="./imagenes/word_count.png" alt="word_count.png" />
</p>
</div>

</section>
<section id="slide-sec-6-4">
<h3 id="sec-6-4">Pseudocódigo</h3>
<pre class="example">
map (String key, String value)
   for each word w in value
      Emit(w, 1)

reduce (String key, Iterator values)
   int wordcount = 0
   for each v in values
      wordcount += v
      Emit(key, wordcount)
</pre>

</section>
<section id="slide-sec-6-5">
<h3 id="sec-6-5">Mockup</h3>
<ul>
<li>Ver los archivos <code>word_count.py</code> y <code>mapreduce.py</code> en la carpeta <code>mock</code>.</li>

</ul>

<pre class="example">
chmod +x word_count.py
python word_count.py
</pre>

<ul>
<li>Este es un ejemplo de mentiritas, no usa Apache Hadoop.</li>

</ul>

</section>
<section id="slide-sec-6-6">
<h3 id="sec-6-6"><code>Hadoop Streaming</code></h3>
<ul>
<li>Es un paquete (<code>jar file</code>) de Java incluido en Hadoop.</li>
<li>Cualquier ejecutable como <i>mapper</i> o <i>reducer</i>.</li>
<li>Lee del <i>stdin</i>, escribe al <i>stout</i>.</li>
<li>Protocolo <code>k\t v\n</code>
<ul>
<li>¡Súper importante!</li>
<li>No recibes <code>k list(v,v,v...)</code></li>

</ul></li>

<li>En pseudocódigo</li>

</ul>

<pre class="example">
cat input_file | mapper | sort | reducer &gt; output_file
</pre>

</section>
<section id="slide-sec-6-7">
<h3 id="sec-6-7">Hadoop Streaming: Ejecución</h3>
<pre class="example">
hadoop jar
$HADOOP_INSTALL/contrib/streaming/*streaming*.jar
-input input_dir
-output output_dir
-mapper my_mapper
-reducer my_reducer
-file my_mapper
-file my_reducer
-jobconf mapred.map.tasks=2
-jobconf mapred.reduce.tasks=2
</pre>

</section>
<section id="slide-sec-6-8">
<h3 id="sec-6-8">Ejercicios</h3>
<ul>
<li>Obtener una lista de formas, usando <code>ufo</code> con <code>Hadoop Streming</code> y <code>bash</code>.
<ul>
<li><i>Tip</i>: Recuerden el comando <code>cut</code> y <code>uniq</code>.</li>

</ul></li>

<li>Obtener una lista de ciudades, estado y su número de avistamientos, usando <code>ufo</code> con <code>Hadoop Streming</code> y <code>bash</code>.</li>

</ul>

</section>
<section id="slide-sec-6-9">
<h3 id="sec-6-9">Hadoop Streaming: Python</h3>
<ul>
<li>Flujo recomendado:</li>
<li>Probamos el <i>mapper</i></li>

</ul>

<div class="org-src-container">

<pre  class="src src-sh">echo "foo foo ernesto david angelica ernesto" | src/wordcount/python/mapper.py
</pre>
</div>

<ul>
<li>Ahora probamos <i>mapper</i> y <i>reducer</i>
<ul>
<li>Nota el <code>sort</code></li>

</ul></li>

</ul>

<div class="org-src-container">

<pre  class="src src-sh">echo "foo foo ernesto david angelica ernesto" | src/wordcount/python/mapper.py | sort -k1.1  | src/wordcount/python/reducer.py
</pre>
</div>

<ul>
<li>Ahora probamos con un archivo</li>

</ul>

<pre class="example">
cat data/books/pg5000.txt | src/wordcount/python/mapper.py
</pre>


</section>
<section id="slide-sec-6-10">
<h3 id="sec-6-10">Hadoop Streaming: Python</h3>
<pre class="example">
$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-*streaming*.jar
-file mapper.py -mapper mapper.py
-file reducer.py -reducer reducer.py
-input books -output books-py-output
</pre>




</section>
</section>
<section>
<section id="slide-sec-7">
<h2 id="sec-7">Pig</h2>
<div class="outline-text-2" id="text-7">
</div></section>
<section id="slide-sec-7-1">
<h3 id="sec-7-1">Pig</h3>
<ul>
<li>Proyecto de Apache</li>
<li>Abstracción encima de Hadoop
<ul>
<li><i>Pig Latin</i> compila a <code>MapReduce</code></li>
<li>En cierta forma <i>Pig Latin</i> es para analistas, <i>data scientist</i> y estadísticos.</li>
<li><code>MapReduce</code>  es para programadores (aunque los <i>data scientist</i> deberían de poder hacerlo también)</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-7-2">
<h3 id="sec-7-2">Pig</h3>
<ul>
<li>Pig es un <i>data flow programming language</i></li>
<li>Es decir,
<ul>
<li>Ejecuta paso a paso</li>
<li>Cada paso es una transformación de datos</li>

</ul></li>
<li>En cambio <code>SQL</code> es un conjunto de <i>constraints</i> que en conjunto definen el resultado buscado.</li>

</ul>

</section>
<section id="slide-sec-7-3">
<h3 id="sec-7-3">Pig</h3>
<ul>
<li>¿Qué cosas puede hacer?
<ul>
<li><code>joins</code></li>
<li><code>sorts</code></li>
<li><code>filters</code></li>
<li><code>group by</code></li>
<li><i>User defined functions</i> <code>UDF</code>'s</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-7-4">
<h3 id="sec-7-4">Pig</h3>
<ul>
<li>¿Qué cosas <b>puedo</b> hacer?

<ul>
<li><code>ETLs</code>
<ul>
<li>Limpiar.</li>
<li><i>Joins</i> gigantes.</li>

</ul></li>

<li>Búsqueda en <i>Raw</i>.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-7-5">
<h3 id="sec-7-5">Pig</h3>
<ul>
<li>Componentes
<ul>
<li><i>Pig Latin</i></li>
<li><code>Grunt</code>
<ul>
<li>Local</li>
<li>MapReduce</li>

</ul></li>
<li><code>Pig compiler</code></li>

</ul></li>

</ul>

</section>
<section id="slide-sec-7-6">
<h3 id="sec-7-6">Pig</h3>
<ul>
<li>Es posible ejecutar también <i>scripts</i> de <i>Pig Latin</i> (terminación <code>.pig</code>) sin entrar a <code>grunt</code>.</li>

</ul>

<pre class="example">
pig script_file.pig

# Si quieren pasar parámetros
pig -p var=bla/bla var2=bla/bla/bla script_file.pig
</pre>

<ul>
<li>Y usarse desde programas en <code>Java</code> con la clase <code>PigServer</code>.
<ul>
<li>Como una especie de <code>JDBC</code>, pero para <i>Pig Latin</i>.</li>

</ul></li>

</ul>


</section>
<section id="slide-sec-7-7">
<h3 id="sec-7-7">Pig: <i>Building blocks</i></h3>
<p>
Fields
</p>
<pre class="example">
'Adolfo'
</pre>

<p>
Tuplas
</p>
<pre class="example">
('Adolfo', 3, 8.17, 23)
</pre>

<p>
<i>Bags</i>
</p>
<pre class="example">
{('Adolfo', 3, 8.17, 23), ('Paty', 3.14, 9, 'A')}
</pre>

</section>
<section id="slide-sec-7-8">
<h3 id="sec-7-8">Ejercicio</h3>
<ol>
<li>Crear una carpeta <code>rita</code> en el <code>HDFS</code>.</li>
<li>Agregar los siguientes archivos:
<ul>
<li><code>airports.csv</code></li>
<li><code>plane_data.csv</code></li>
<li><code>carriers.csv</code></li>

</ul></li>
<li>Ejecutar <code>grunt</code>.</li>

</ol>

<pre class="example">
# Pig latin puede ejecutar comandos del hdfs
cat rita/airports
# Especificando el separador (,) y el esquema (no es necesario)
airports = load 'rita/airports' using PigStorage(',') as (iata:chararray, ..., latitude:float, ...);
# Hasta este momento se ejecuta todo...
dump airports;
# El comando store guarda al HDFS y también ejecuta todo.
</pre>

</section>
<section id="slide-sec-7-9">
<h3 id="sec-7-9">Ejercicio</h3>
<pre class="example">
a_imprimir = limit airports 5;
por_estado = group airports by state;
describe por_estado;
explain por_estado;
illustrate por_estado;
# itera sobre cada elemento del bag
conteo = foreach por_estado generate group count_star(airports);
ordenados = order conteo by $1 desc;
top_five = limit ordenado 5;
unicos = distinct conteos;
muestreo = sample por_estado 0.1;
filtrados = filter conteos by substring(group, 0, 2) == 'W';
mayores = filter conteos by $1 &gt; 50;
</pre>

</section>
<section id="slide-sec-7-10">
<h3 id="sec-7-10">Ejercicio: Trucos del <code>foreach</code></h3>
<pre class="example">
# Proyectar
foreach airports generate iata, airport, country;

# Expresiones posicionales
# $1 -&gt; iata
# $3 -&gt; city
# $5 -&gt; country

# Rangos
# ..country, iata..country, latitude..

# Tokenizar
tokens = foreach lineas generate tokenize(linea);
# Cada fila obtenida es un bag de palabras.
</pre>

</section>
<section id="slide-sec-7-11">
<h3 id="sec-7-11">Pig: JOINS</h3>
<ol>
<li>Cargamos fuente 1</li>
<li>Cargamos fuente 2</li>
<li>Unimos las fuentes (<i>bags</i>) mediante una llave</li>
<li>Súper simple</li>

</ol>

<p>
Pig soporta <i>inner joins</i> (valor por omisión), <i>left outer joins</i> (y
<i>right</i> también) y <i>full outer</i> joins.
</p>


<pre class="example">
fuentes_unidas = join fuente1 by (keys) [left|right|full outer] fuente2 by (keys);
</pre>

<p>
Además <code>Pig</code> soporta <code>cogroup</code> además de los <code>joins</code> (el <code>cogroup</code>
preserva la estructura de las fuentes y crea tuplas por cada llave)
</p>

<pre class="example">
fuentes_unidas = cogroup fuente1 by (keys) fuente2 by (keys);
</pre>


</section>
<section id="slide-sec-7-12">
<h3 id="sec-7-12">Pig: Ejemplo de JOINs y COGROUPs</h3>
<pre class="example">
# Fuentes de datos

mascotas: (dueño, mascotas)
----------------------
(Adolfo, tortuga)
(Adolfo, pez)
(Adolfo, gato)
(Paty, perro)
(Paty, gato)

amigos: (amigo1, amigo2)
----------------------
(Diana, Adolfo)
(Gabriel, Adolfo)
(Shanti, Paty)


COGROUP mascotas by dueño, amigos por amigo2;
---------------------------------------------
(Adolfo, {(Adolfo, tortuga), (Adolfo, pez), (Adolfo, gato)}, {(Diana, Adolfo), (Gabriel, Adolfo)})
(Paty, {(Paty, perro), (Paty, gato)}, {(Shanti, Paty)})

JOIN mascotas by dueño, amigos por amigo2;
-------------------------------------------
(Adolfo, tortuga, Diana)
(Adolfo, tortuga, Gabriel)
(Adolfo, pez, Diana)
(Adolfo, pez, Gabriel)
(Adolfo, gato, Diana)
(Adolfo, gato, Gabriel)
(Paty, perro, Shanti)
(Paty, gato, Shanti)
</pre>

</section>
<section id="slide-sec-7-13">
<h3 id="sec-7-13">Aclaraciones sobre GROUP y FLATTEN</h3>
<ul>
<li><code>FLATTEN</code> elimina un nivel anidamiento</li>

</ul>

<pre class="example">
# Datos:
# (Adolfo, (tortuga, pez, gato))
# (Paty, (perro, gato))
# FLATTEN eliminaría los bags internos
(Adolfo, tortuga)
(Adolfo, pez)
(Adolfo, gato)
(Paty, perro)
(Paty, gato)
</pre>

<ul>
<li><code>GROUP .. BY</code> organiza los <i>bags</i> en <i>bags</i></li>

</ul>
<pre class="example">
# Siguiendo con los datos anteriores de mascotas
GROUP mascotas BY dueño;

# ( Adolfo, {(Adolfo, tortuga), (Adolfo, pez), (Adolfo, gato)} )
# ( Paty, {(Paty, perro), (Paty, gato)} )
</pre>

<ul>
<li>En cierto sentido <code>FLATTEN</code> y <code>GROUP .. BY</code> son operaciones inversas
entre sí.</li>

</ul>

</section>
<section id="slide-sec-7-14">
<h3 id="sec-7-14">Tarea</h3>
<p>
Crear un <code>wordcount</code> para los archivos en <code>data</code> usando <code>Pig</code>
</p>


</section>
</section>
<section>
<section id="slide-sec-8">
<h2 id="sec-8">Hive</h2>
<div class="outline-text-2" id="text-8">
</div></section>
<section id="slide-sec-8-1">
<h3 id="sec-8-1">Hive</h3>
<ul>
<li><i>Datawarehouse</i>.</li>
<li><code>HQL</code> es casi idéntico a <code>SQL</code>.</li>
<li>Proyecto de Apache.</li>
<li>Estructura a diversos formatos.</li>
<li><i>Queries</i>.</li>
<li>Acceso al <code>HDFS</code> y <code>HBASE</code>.</li>
<li><i>Queries</i> en tiempo real.</li>
<li>Facilidad de uso.</li>

</ul>

</section>
<section id="slide-sec-8-2">
<h3 id="sec-8-2">Arquitectura de Apache Hive</h3>

<div class="figure">
<p><img src="./imagenes/hive-remote.jpeg" alt="hive-remote.jpeg" />
</p>
</div>

</section>
<section id="slide-sec-8-3">
<h3 id="sec-8-3">Ejercicio: Crear RITA en Hive</h3>
<pre class="example">
CREATE EXTERNAL TABLE carriers(
code STRING,
description STRING
)
COMMENT 'Códigos de carriers'
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' STORED AS TEXTFILE;

CREATE EXTERNAL TABLE airports(
iata STRING,
airport STRING,
city STRING,
state STRING,
country STRING,
latitude FLOAT,
longitude FLOAT
)
COMMENT 'Códigos y localización de aeropuertos'
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' STORED AS TEXTFILE;

CREATE EXTERNAL TABLE planes_data(
tailnum STRING,
type STRING,
manufacturer STRING,
issue_date STRING,
model STRING,
status STRING,
aircraft_type STRING,
engine_type STRING,
year STRING
)
COMMENT 'Datos de algunos aviones mencionados en RITA'
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' STORED AS TEXTFILE;
</pre>


</section>
<section id="slide-sec-8-4">
<h3 id="sec-8-4">Ejercicio: Crear RITA en Hive</h3>
<pre class="example">
CREATE EXTERNAL TABLE rita(
Year STRING,
Month STRING,
DayofMonth STRING,
DayOfWeek STRING,
DepTime STRING,
CRSDepTime STRING,
ArrTime STRING,
CRSArrTime STRING,
UniqueCarrier STRING,
FlightNum STRING,
TailNum STRING,
ActualElapsedTime INT,
CRSElapsedTime INT,
AirTime INT,
ArrDelay INT,
DepDelay INT,
Origin STRING,
Dest STRING,
Distance FLOAT,
TaxiIn INT,
TaxiOut INT,
Cancelled INT,
CancellationCode STRING,
Diverted INT,
CarrierDelay INT,
WeatherDelay INT,
NASDelay INT,
SecurityDelay INT,
LateAircraftDelay INT
)
COMMENT 'Base de datos conteniendo los vuelos de 1987 a 2008'
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' STORED AS TEXTFILE LOCATION '/user/hive/rita';
</pre>

</section>
<section id="slide-sec-8-5">
<h3 id="sec-8-5">Ejercicio: RITA y HIVE</h3>
<pre class="example">
-- ¿Se crearon bien las tablas?
show tables;

-- ¿Se cargó bien rita?
select * from rita limit 5;

-- Cargamos airports
load data inpath 'hive/datawarehouse/rita/catalogs/airports.csv'
overwrite into table airports;

-- Probamos
select * from airports where iata='SAN';

-- ¿Y si hacemos un JOIN?

select * from rita join airports on (rita.Origin = airports.iata) limit 10;
-- ¿Qué pasó?
</pre>

</section>
<section id="slide-sec-8-6">
<h3 id="sec-8-6">Tarea</h3>
<p>
Crear un <code>wordcount</code> para los archivos en <code>data</code> usando <code>Hive</code>
</p>



</section>
</section>
<section>
<section id="slide-sec-9">
<h2 id="sec-9">Ejercicios</h2>
<div class="outline-text-2" id="text-9">
</div></section>
<section id="slide-sec-9-1">
<h3 id="sec-9-1">RITA, HIVE y PIG</h3>
<pre class="example">
register /home/hduser/hadoop-src/pig-0.12.0/contrib/piggybank/java/piggybank.jar;
define replace org.apache.pig.piggybank.evaluation.string.REPLACE;
define substring org.apache.pig.piggybank.evaluation.string.SUBSTRING;
define s_split org.apache.pig.piggybank.evaluation.string.Split;
define reverse org.apache.pig.piggybank.evaluation.string.Reverse;

airports = LOAD '/user/nano/rita_catalogs/airports.csv'
USING PigStorage(',')
AS
(iata:chararray,airport:chararray,city:chararray,
state:chararray,country:chararray,latitude:float,longitude:float);

fixed_airports = foreach airports
                 generate replace(iata, '"', ''),
                          replace(airport, '"', ''),
                          replace(city, '"', ''),
                          replace(state, '"', ''),
                          replace(country, '"', ''),
                          latitude, longitude;

store fixed_airports into '/user/pig/airports-fixed' using PigStorage(',');
</pre>

</section>
<section id="slide-sec-9-2">
<h3 id="sec-9-2">RITA y HIVE: Joins</h3>
<pre class="example">
load data inpath 'pig_fixed/airports/part-m-00000'
overwrite into table airports;

-- ¿Y ahora?
select * from airports where iata='SAN';

select * from rita join airports on (rita.Origin = airports.iata) limit 10;
</pre>



</section>
<section id="slide-sec-9-3">
<h3 id="sec-9-3">Tarea: Pig y Hive</h3>
<ul>
<li>Crear una tabla de RITA limpia (usando <code>PIG</code> y <code>HIVE</code>)</li>
<li>Ejecutar dos exploraciones de las tareas de analítica de PostgreSQL,
uno usando <code>PIG</code> y otro usando <code>HIVE</code>.</li>

</ul>

</section>
<section id="slide-sec-9-4">
<h3 id="sec-9-4">¡Más ejercicios!</h3>
<ul>
<li>Usando <code>RITA</code> (lo que tengan cargado en su nodo), calcule:
<ul>
<li>Con <code>Pig</code>:
<ul>
<li>El número de vuelos por aeropuerto.</li>
<li>¿Cuál es el más activo?</li>

</ul></li>
<li>Con <code>Hive</code>:
<ul>
<li>Número de <code>km</code> por avión.</li>
<li>¿Cuál es el <i>top</i> 5?</li>
<li>¿Sería más fácil en <code>Pig</code>?</li>

</ul></li>

</ul></li>

</ul>

</section>
<section id="slide-sec-9-5">
<h3 id="sec-9-5">¡Más ejercicios!</h3>
<ul>
<li>Lo que sigue, son de los pocos algoritmos de <i>grafos</i> que se pueden ejecutar en Hadoop&#x2026;</li>

<li>Similitud de <b>Jaccard</b>
<ul>
<li>También conocida como <i>similitud estructural</i>.</li>
<li><code>RITA</code> se puede armar como un <i>grafo</i>  y queremos obtener los nodos (aeropuertos) que son similares.</li>
<li>J(A,B) = \frac{|A \cap B|}{|A \cup B|} = \frac{|A \cap B|}{|A|+|B|-|A \cap B|}</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-9-6">
<h3 id="sec-9-6">¡Más ejercicios!</h3>

<div class="figure">
<p><img src="./imagenes/ejercicio_grafos.png" alt="ejercicio_grafos.png" />
</p>
</div>


</section>
<section id="slide-sec-9-7">
<h3 id="sec-9-7">Tarea</h3>
<ul>
<li>Bajar la fuente de datos de  <a href="http://www.infochimps.com/datasets/marvel-universe-social-graph">aquí</a>.</li>

<li>Aplicar la <i>similitud de Jaccard</i> a este <i>set</i>.</li>

<li>Obtener los más parecidos al <b>Capitán América</b>.</li>

<li>Artículos:
<ul>
<li><a href="http://arxiv.org/abs/cond-mat/0202174">Marvel Universe looks almost like a real social network</a></li>
<li><a href="http://arxiv.org/abs/0708.2410">How to become a superhero</a></li>

</ul></li>

</ul>


</section>
<section id="slide-sec-9-8">
<h3 id="sec-9-8">¡Más <i>grafos</i>!</h3>
<ul>
<li><b>degree of a node</b> = Número de conexiones a otros nodos</li>
<li><b>degree distribution</b> = Distribución de probabilidad en los <i>degrees</i> sobre todo el <i>grafo</i>.</li>

<li><code>P(k)</code> = Fracción de nodos del <i>grafo</i> con grado <code>k</code>,
<ul>
<li>Es decir: <code>P(k) = n_k/n</code></li>

</ul></li>

</ul>

</section>
<section id="slide-sec-9-9">
<h3 id="sec-9-9">¡Más <i>grafos</i>!</h3>
<p>
Entonces, en <code>RITA</code> podemos definir como grado el número siguiente:
</p>
<ul>
<li>Por cada aeropuerto, el número de vuelos que llegan más el número de vuelos que salen
<ul>
<li>Para hacerlo temporal, incluiremos el mes</li>
<li>¿Se les ocurre otra forma?</li>

</ul></li>

</ul>


</section>
<section id="slide-sec-9-10">
<h3 id="sec-9-10">¡Más <i>grafos</i>!</h3>
<pre class="example">
grunt&gt; vuelos =
# Si no están en este formato hacer un ETL a:
# origen destino vuelo mes||año

# Transformamos:
grunt&gt; aeropuertos_salidas =
# Sólo aeropuerto, mes, vuelos_entrada
grunt&gt; aeropuertos_entrada =
# idem

# Unimos
grunt&gt; agrupados = COGROUP aeropuertos_entradas BY (aeropuerto, mes), aeropuertos_salidas BY (aeropuerto, mes)
# ¿Por qué COGROUP y no JOIN?

# Sumamos
grunt&gt; degree_dist = FOREACH agrupados {
               vuelos_degree = SUM(aeropuertos_entrada.vuelos_entrada) + SUM(aeropuertos_salida.vuelos_salida)
               GENERATE
                FLATTEN(group) AS (aeropuerto, mes),
                vuelos_degree AS vuelos_degree
              ;
};

# Guardamos
grunt&gt; STORE degree_dist INTO ... ;
</pre>

</section>
<section id="slide-sec-9-11">
<h3 id="sec-9-11">¡Más <i>grafos</i>!</h3>
<ul>
<li>¿Qué distribución tiene?</li>

<li><b>Ejercicio</b>: Graficarlo en R.
<ul>
<li>Obtener el resultado con <code>hdfs</code> y luego usarlo en <code>R</code> mostrar la temporalidad con <code>ggplot2</code>.</li>

</ul></li>

<li><b>Tarea</b> ¿Alguna medida de grado para el <i>dataset</i> de superhéroes?
<ul>
<li>¿Qué distribución tiene?</li>

</ul></li>

<li>Más artículos:
<ul>
<li><a href="http://arxiv.org/abs/cond-mat/0106096">Statistical mechanics of complex networks</a></li>
<li><a href="http://arxiv.org/abs/cond-mat/0106144">Evolution of networks</a></li>
<li><a href="http://arxiv.org/abs/cond-mat/0303516">The structure and function of complex networks</a></li>

</ul></li>

</ul>


</section>
<section id="slide-sec-9-12">
<h3 id="sec-9-12">Otro truco en <code>Hive</code></h3>
<ul>
<li>Si no saben <code>PigLatin</code> aún es posible limpiar en <code>Hive</code>.</li>

<li>Creen una tabla con una sola columna y carguen un año de <code>RITA</code></li>

</ul>

<pre class="example">
create table temp_rita (columnota STRING);
LOAD DATA INPATH '/user/rita/2000.csv' OVERWRITE INTO TABLE temp_rita;
</pre>

<ul>
<li>Ahora creen una tabla con la estructura de las columnas que quieran
extraer o limpiar</li>

</ul>

<pre class="example">
create table rita (col_1 STRING, col_2 INT, ....);
# Y para extraerlas usen
insert overwrite table rita
select
regexp_extract(columnota, 'expresión_regular', 1) col_1,
regexp_extract(columnota, 'expresión_regular', 1) col_2,
...
from temp_rita
</pre>

<ul>
<li>Un ejemplo de expresión regular sería</li>

</ul>
<pre class="example">
^(?:([^,]*)\,?)'
</pre>
<p>
y luego usen un cuantificador para extraer la columna que deseen.
</p>




</section>
</section>
<section>
<section id="slide-sec-10">
<h2 id="sec-10">HCatalog</h2>
<div class="outline-text-2" id="text-10">
</div></section>
<section id="slide-sec-10-1">
<h3 id="sec-10-1">HCatalog</h3>
<ul>
<li>Está incorporado a <code>Hive</code> desde la versión <code>0.11</code>.</li>

<li>Es una capa administrativa de tablas y almacenamiento que permite
que diferentes herramientas de procesamiento de datos (<code>Pig</code>,
<code>MapReduce</code>) puedan leer y escribir más fácilmente del <code>HDFS</code>.</li>
<li>Contiene una abstracción que presenta una vista relacional de los
datos contenidos en el <code>HDFS</code>, asegurando que los usuarios no se
preocupen dónde o en que formato están almacenados los datos.</li>

</ul>

</section>
<section id="slide-sec-10-2">
<h3 id="sec-10-2">HCatalog</h3>
<ul>
<li>Utiliza el <code>DDL</code> de <code>Hive</code>.</li>
<li>Provee interfaces de escritura y lectura para <code>Pig</code>, <code>MapReduce</code> y
<code>Hive</code>.</li>
<li>Usa la línea de comandos para manejar la definición de los datos y
metadatos.</li>
<li><code>HCatalog</code> presenta los datos de manera relacional.</li>
<li>Los datos son guardados en tablas y las tablas en bases de datos.</li>

<li><code>WebHCat</code> es la interfaz API <code>REST</code> de <code>HCatalog</code>.</li>

</ul>

</section>
<section id="slide-sec-10-3">
<h3 id="sec-10-3">HCatalog: Flujo de datos</h3>
<ul>
<li>Usuario 1 copia datos al HDFS</li>

</ul>
<pre class="example">
hadoop distcp file:///data/books/pg2047.txt hdfs://data/20140430/books
hcat "alter table books add partition (ds='20140430') location 'hdfs://data/20140430/books'"
</pre>

<ul>
<li>Usuario 2 usa <code>Pig</code> para limpiar y preparar los datos.
<ul>
<li><code>HCatalog</code> mandará al <code>JMS</code> un mensaje de que la información está disponible.</li>

</ul></li>

</ul>

<pre class="example">
A = load 'books' using HCatLoader();
B = filter A by date = '20140430';
...
store Z into 'procesados' using HCatStorer("date=20140430");
</pre>

<ul>
<li>Usuario 3 realiza cierta analítica</li>

</ul>
<pre class="example">
select col1, count(col3)
from procesados
where date  = '201340430'
group by col1;
</pre>

</section>
</section>
<section>
<section id="slide-sec-11">
<h2 id="sec-11">HBase</h2>
<div class="outline-text-2" id="text-11">
</div></section>
<section id="slide-sec-11-1">
<h3 id="sec-11-1">CAP Theorem</h3>

<div class="figure">
<p><img src="./imagenes/cap.png" alt="cap.png" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-sec-12">
<h2 id="sec-12">Apache Sqoop</h2>
<div class="outline-text-2" id="text-12">
</div></section>
<section id="slide-sec-12-1">
<h3 id="sec-12-1">Apache Sqoop</h3>
<ul>
<li>Herramienta para importar eficientemente <i>data</i> desde <code>RDBMS</code> a Hadoop (<code>HDFS,
  Hive, Hbase</code>) y viceversa.</li>
<li>Soporta cualquier <code>RDBMS</code> que tenga conexión <code>JDBC</code> (<code>PostgreSQL, MySQL, Oracle, Teradata</code>, etc.).</li>
<li>Tiene soporte nativo para <code>MySQL</code> y <code>PostgreSQL</code>.</li>

</ul>

</section>
<section id="slide-sec-12-2">
<h3 id="sec-12-2">Apache Sqoop</h3>

<div class="figure">
<p><img src="./imagenes/sqoop.png" alt="sqoop.png" />
</p>
</div>

</section>
<section id="slide-sec-12-3">
<h3 id="sec-12-3">Ejercicio: RITA del tingo al tango</h3>

</section>
</section>
<section>
<section id="slide-sec-13">
<h2 id="sec-13">Apache Flume</h2>

</section>
</section>
<section>
<section id="slide-sec-14">
<h2 id="sec-14">Apache Spark</h2>

</section>
</section>
<section>
<section id="slide-sec-15">
<h2 id="sec-15">Oozie</h2>

</section>
</section>
<section>
<section id="slide-sec-16">
<h2 id="sec-16">Hue</h2>

</section>
</section>
<section>
<section id="slide-sec-17">
<h2 id="sec-17"><i>Cluster</i> de Hadoop</h2>
<div class="outline-text-2" id="text-17">
</div></section>
<section id="slide-sec-17-1">
<h3 id="sec-17-1">Preliminares: NTP</h3>
<ul>
<li>Los relojes de todos los nodos del <i>cluster</i> deben de poder
sincronizarse, por lo que es necesario instalar <b>NTP</b> (<i>Network
Time Protocol</i>) en todos los nodos y un servidor <b>NTP</b> en el nodo maestro.</li>

</ul>

<pre class="example">
sudo apt-get install ntp # en cada nodo
# Habilitar el servicio
chkconfig ntpd on # en cada nodo
# Iniciar el servicio
/etc/init.d/ntpd start # en cada nodo
# Configurar los clientes para usar el servidor NTP local
# en el archivo /etc/ntp.conf
server $IP_SERVIDOR_LOCAL
</pre>

</section>
<section id="slide-sec-17-2">
<h3 id="sec-17-2">Preliminares: DNS</h3>
<ul>
<li>Todos los nodos deben de estar configurados para <code>DNS</code> y <code>Reverse
  DNS</code></li>

</ul>

<p>
Primero verifiquemos que funcione el <i>forward lookup</i>:
</p>

<pre class="example">
nslookup host01
# Debería de devolver:
# Name: host01.dominio
# Address: ip_address
</pre>

<p>
Y el <i>reverse lookup</i>
</p>

<pre class="example">
nslookup ip_address
# Debería de devolver:
x.x.x.x.in-addr.arpa  name=host01.dominio
</pre>

<p>
Si esto falla hay dos opciones
</p>

<ol>
<li>Modificar  en <i>cada nodo</i> el <code>/etc/hosts</code> y agregar todos los nodos
(incluido el mismo)</li>

</ol>

<pre class="example">
ip_address name
</pre>

<ol>
<li>Configurar un servidor de <code>DNS</code> con <code>bind</code> (No se verá aquí).</li>

</ol>

</section>
<section id="slide-sec-17-3">
<h3 id="sec-17-3">Preliminares: SELinux</h3>
<ul>
<li>Si tienen habilitado <b>SELinux</b> <i>Security Enhaced Linux</i> , hay que
deshabilitarlo
<ul>
<li>Es muy probable que si están en una <code>distro</code> basada en <code>Debian</code> no
esté instalado por <i>default</i>.</li>
<li>Pueden verificarlo tecleando <code>getenforce</code> en la línea de comandos.</li>
<li>Si dice que no está instalado, o responde <code>permissive</code> o
<code>disabled</code>, ya no hay que hacer nada.</li>
<li>En caso contrario, seguir las instrucciones para desactivarlo (No
se ve aquí, no usamos <code>distros</code> basadas en <code>Red Hat</code>).</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-17-4">
<h3 id="sec-17-4">Preliminares: Firewall</h3>
<ul>
<li>Deshabiliten el <code>firewall</code></li>

</ul>

<pre class="example">
service ufw stop
</pre>

<ul>
<li>Recuerden que están en una red privada, no hay manera de acceder a
ella desde afuera.</li>

</ul>

</section>
<section id="slide-sec-17-5">
<h3 id="sec-17-5">Preliminares: Usuarios</h3>
<p>
-Hay que definir los siguientes usuarios y grupos:
</p>

<p>
<code>HDFS_USER</code>, <code>YARN_USER</code>, <code>ZOOKEEPER_USER</code>,
<code>HIVE_USER</code>, <code>MAPREDUCE_USER</code>, <code>OOZIE_USER</code>
<code>WEBHCAT_USER</code>, <code>HBASE_USER</code>, <code>PIG_USER</code> y <code>HADOOP_GROUP</code>.
</p>

<p>
Por ejemplo:
</p>

<pre class="example">
| Servicio             | User      | Grupo  |
|----------------------+-----------+--------|
| HDFS                 | hdfs      | hadoop |
| YARN                 | yarn      | hadoop |
| MapReduce            | mapred    | hadoop |
| Hive                 | hive      | hadoop |
| Pig                  | pig       | hadoop |
| HCatalog/WebHCatalog | hcat      | hadoop |
| HBase                | hbase     | hadoop |
| ZooKeeper            | zookeeper | hadoop |
| Oozie                | oozie     | hadoop |
</pre>

<p>
cada uno de ellos ejecutará y poseerá los servicios que hay que levantar.
</p>

</section>
<section id="slide-sec-17-6">
<h3 id="sec-17-6">Preliminares: SSH</h3>
<ul>
<li>Los usuarios deben de poder conectarse en todos los nodos (<b>todos</b>).</li>
<li>Hay que crear las llaves con <code>ssh-keygen</code> y distribuirlas con
<code>ssh-copy-id</code></li>

</ul>

<pre class="example">
ssh-keygen -t rsa -C "your_email@example.com"
ssh-copy-id user@ipaddress
</pre>

</section>
<section id="slide-sec-17-7">
<h3 id="sec-17-7">Preliminares: Directorios</h3>
<ul>
<li>Núcleares</li>

</ul>


<pre class="example">
| Servicio  | Parámetro         | Definición |
|-----------+-------------------+------------|
| HDFS      | DFS_NAME_DIR      |            |
| HDFS      | DFS_DATA_DIR      |            |
| HDFS      | FS_CHECKPOINT_DIR |            |
| HDFS      | HDFS_LOG_DIR      |            |
| HDFS      | HDFS_PID_DIR      |            |
| HDFS      | HADOOP_CONF_DIR   |            |
| YARN      | YARN_LOCAL_DIR    |            |
| YARN      | YARN_LOG_DIR      |            |
| YARN      | YARN_PID_DIR      |            |
| MapReduce | MAPRED_LOG_DIR    |            |
</pre>

</section>
<section id="slide-sec-17-8">
<h3 id="sec-17-8">Preliminares: Directorios</h3>
<ul>
<li>Ecosistema</li>

</ul>

<pre class="example">
| Servicio  | Parámetro          | Definición |
|-----------+--------------------+------------|
| Pig       | PIG_CONF_DIR       |            |
| Pig       | PIG_LOG_DIR        |            |
| Pig       | PIG_PID_DIR        |            |
| Oozie     | OOZIE_CONF_DIR     |            |
| Oozie     | OOZIE_DATA         |            |
| Oozie     | OOZIE_LOG_DIR      |            |
| Oozie     | OOZIE_PID_DIR      |            |
| Oozie     | OOZIE_TMP_DIR      |            |
| Hive      | HIVE_CONF_DIR      |            |
| Hive      | HIVE_LOG_DIR       |            |
| Hive      | HIVE_PID_DIR       |            |
| WebHcat   | WEBHCAT_CONF_DIR   |            |
| WebHcat   | WEBHCAT_LOG_DIR    |            |
| WebHcat   | WEBHCAT_PID_DIR    |            |
| Hbase     | HBASE_CONF_DIR     |            |
| Hbase     | HBASE_LOG_DIR      |            |
| Hbase     | HBASE_PID_DIR      |            |
| Zookeeper | ZOOKEEPER_DATA_DIR |            |
| Zookeeper | ZOOKEEPER_CONF_DIR |            |
| Zookeeper | ZOOKEEPER_LOG_DIR  |            |
| Zookeeper | ZOOKEEPER_PID_DIR  |            |
| Sqoop     | SQOOP_CONF_DIR     |            |
</pre>


</section>
<section id="slide-sec-17-9">
<h3 id="sec-17-9">Preliminares: Base de datos</h3>
<p>
Algunos componentes de <code>Apache Hadoop</code>, (como <code>HIVE</code>, <code>Zookeeper</code>)
requieren de una base de datos relacional para funcionar.
</p>

<p>
Se recomienda instalar <code>PostgreSQL</code>, instale y configure como se vió
en la lección 4 de este curso. Será necesario tener el <code>driver JDBC</code>,
no se te olvide.
</p>


</section>
<section id="slide-sec-17-10">
<h3 id="sec-17-10">¿Qué Hardware necesito?</h3>
<ul>
<li>¿Cuántos datos va a contener el <i>cluster</i>?</li>
<li>¿Cuáles son las proyecciones de crecimiento de los datos?</li>
<li>¿El <i>cluster</i> será usado para tareas programadas en lote?</li>
<li>¿Será usado para análisis exploratorio de datos?</li>
<li>¿Ambos?</li>

</ul>



</section>
<section id="slide-sec-17-11">
<h3 id="sec-17-11">Hardware: <i>DataNode</i></h3>
<ul>
<li>Cumplen dos funciones: Almacenan piezas de los datos del <code>HDFS</code> y
ejecutan tareas <code>MapReduce</code>.</li>

<li>Deben de ser lo suficientemente rápidos para
ejecutar bien la tarea, pero baratos para ser remplazados
rápidamente si fallan (Son desechables).</li>

<li>Debido a la redundancia que provee el <code>HDFS</code> no es necesario pensar en
arreglos <code>RAID</code> para estos componentes, la opción preferida es
<code>JBOD</code> <i>Just a Bunch Of Disks</i>.</li>

<li>El <code>DataNode</code> debe de poseer almacenamiento y poder de cómputo.</li>

</ul>

</section>
<section id="slide-sec-17-12">
<h3 id="sec-17-12">Hardware: <i>DataNode</i></h3>
<ol>
<li>Identificar las fuentes de datos.
<ul>
<li>Piensa en 20% a 30% más de la capacidad del <i>cluster</i> por si hay
nuevos datos.</li>

</ul></li>
<li>Estimar la tasa de crecimiento de los datos.</li>
<li>Multiplica los requerimientos de almacenamiento por el factor de
replicación (por <i>default</i> es <b>3</b>).
<ul>
<li>Ejemplo: Si estimaste <code>3 TB</code> en un año, serían <code>9 TB</code> la
capacidad requerida del <i>cluster</i>.</li>

</ul></li>
<li>Archivos temporales de <code>MapReduce</code>.
<ul>
<li><code>MapReduce</code> produce archivos que son pasados de la fase de mapeo
a la de reducción, estos no residen en el <code>HDFS</code>, se recomienda
apartar del 25% al 30% de la capacidad de disco para estos
archivos.</li>

</ul></li>

</ol>

</section>
<section id="slide-sec-17-13">
<h3 id="sec-17-13">Hardware: <i>DataNode</i></h3>
<ul>
<li>No vale la pena comprar discos de 15000 rpm para el
<i>cluster</i>. Haddop realiza (principalmente) lectura/escritura
<i>secuencial</i>, más que aleatoria, por lo que discos de <b>7200 rpm</b> son
suficientes.</li>

<li><i>Cluster</i> de baja densidad
<ul>
<li>Objetivo: Nodos de bajo costo.</li>
<li>6 <i>slots</i> para <code>HDD</code>, con discos de 2 TB, nos dan 12 TB por
servidor.</li>
<li>2 CPUs de 4 <i>cores</i> (cada tarea de map o reduce utiliza un sólo
<i>core</i>, si abusamos un poco podemos tener hasta 12 <i>slots</i> de
map/reduce por nodo)</li>
<li>Cada tarea requiere de 2 a 4 GB de RAM, 36 GB serían razonables,
pero 48GB por nodo es una opción mejor.</li>
<li>Interfaces de 1GbE, utilizando la mayor cantidad de tarjetas de red</li>
<li><b>Ejercicio:</b> ¿Cuántos servidores se requerirían para <code>500TB</code>?</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-17-14">
<h3 id="sec-17-14">Hardware: <i>DataNode</i></h3>
<ul>
<li><i>Cluster</i> de alta densidad
<ul>
<li>Objetivo: Un <i>cluster</i> más compacto, con mayor poder por nodo.
<ul>
<li>No se requiere tener cantidades enormes de datos.</li>
<li><i>Machine learning</i>, <i>EDA</i>, etc.</li>

</ul></li>
<li>Cada nodo con 16x2 TB en <code>HDD</code> o 24x1TB.</li>
<li>16 CPUs y 96 GB de RAM.</li>
<li>Interfaz de 10 GbE.</li>

</ul></li>

</ul>

</section>
<section id="slide-sec-17-15">
<h3 id="sec-17-15">Hardware: <i>Namenode</i></h3>
<ul>
<li>El <i>Namenode</i> es crítico en la disponibilidad del <code>HDFS</code>.</li>
<li>Almacena todo el metadata del <i>filesystem</i>: que bloques con que
archivos, en que <i>datanodes</i> están esos bloques, cuántos bloques
están disponibles y que servidores pueden contenerlos. Toda esta
información debe de estar en memoria.</li>

<li>Cada bloque ocupa 250 bytes de RAM y 250 bytes de RAM por cada
archivo y directorio.
<ul>
<li>¿Cuánto sería necesario por 5000 archivos de 20 GB cada uno?</li>

</ul></li>

</ul>


</section>
<section id="slide-sec-17-16">
<h3 id="sec-17-16">Hardware: <code>YARN</code>, <code>MapReduce</code></h3>
<ul>
<li><code>YARN</code> toma en cuenta los recursos completos del nodo, para negociar
las peticiones de recursos de las aplicaciones corriendo en el <i>cluster</i> (un ejemplo sería <code>MapReduce</code>).</li>

<li><code>YARN</code> provee esos recursos a cada aplicación en la forma de un
<b>Contenedor</b>.</li>

<li>Es una buena práctica, permitir 2 contenedores por disco por <i>core</i>.</li>

</ul>

</section>
<section id="slide-sec-17-17">
<h3 id="sec-17-17">Hardware: <code>YARN</code>, <code>MapReduce</code></h3>
<ul>
<li>En cada nodo, hay que tomar en cuenta la cantidad reservada para los
procesos del sistema que <b>no son</b> Hadoop.</li>

</ul>


<pre class="example">
| Total Memory per Node | Recommended Reserved System Memory |
|-----------------------+------------------------------------|
| 4 GB                  | 1 GB                               |
| 8 GB                  | 2 GB                               |
| 16 GB                 | 2 GB                               |
| 24 GB                 | 4 GB                               |
| 48 GB                 | 6 GB                               |
| 64 GB                 | 8 GB                               |
| 72 GB                 | 8 GB                               |
| 96 GB                 | 12 GB                              |
| 128 GB                | 24 GB                              |
| 256 GB                | 32 GB                              |
| 512 GB                | 64 GB                              |
</pre>

<ul>
<li>Luego hay que calcular el número máximo de contenedores por nodo</li>

</ul>

<pre class="example">
# de contenedores = min(2*cores, 1.8*discos, (RAM total disponible)/MIN_CONTAINER_SIZE)
</pre>

</section>
<section id="slide-sec-17-18">
<h3 id="sec-17-18">Hardware: <code>YARN</code>, <code>MapReduce</code></h3>
<p>
Donde el <code>MIN_CONTAINER_SIZE</code> se toma de la siguiente tabla
</p>

<pre class="example">
| RAM total por nodo     | Tamaño mínimo del contenedor       |
|------------------------+------------------------------------|
| Less than 4 GB         | 256 MB                             |
| Between 4 GB and 8 GB  | 512 MB                             |
| Between 8 GB and 24 GB | 1024 MB                            |
| Above 24 GB            | 2048 MB                            |
</pre>


<p>
Luego, hay que calcular
</p>

<pre class="example">
RAM_por_contenedor = max(MIN_CONTAINER_SIZE, (RAM total disponible)/Contenedores)
</pre>

</section>
<section id="slide-sec-17-19">
<h3 id="sec-17-19">Hardware: <code>YARN</code>, <code>MapReduce</code></h3>
<p>
Con estos cálculos se obtiene la siguiente tabla:
</p>


<pre class="example">
| Configuration File    | Configuration Setting                | Value Calculation                |
|-----------------------+--------------------------------------+----------------------------------|
| yarn-site.xml         | yarn.nodemanager.resource.memory-mb  |  Containers * RAM-per-Container |
| yarn-site.xml         | yarn.scheduler.minimum-allocation-mb |  RAM-per-Container              |
| yarn-site.xml         | yarn.scheduler.maximum-allocation-mb |  containers * RAM-per-Container |
| mapred-site.xml       | mapreduce.map.memory.mb              |  RAM-per-Container              |
| mapred-site.xml       | mapreduce.reduce.memory.mb           |  2 * RAM-per-Container          |
| mapred-site.xml       | mapreduce.map.java.opts              |  0.8 * RAM-per-Container        |
| mapred-site.xml       | mapreduce.reduce.java.opts           |  0.8 * 2 * RAM-per-Container    |
| yarn-site.xml (check) | yarn.app.mapreduce.am.resource.mb    |  2 * RAM-per-Container          |
| yarn-site.xml (check) | yarn.app.mapreduce.am.command-opts   |  0.8 * 2 * RAM-per-Container    |
</pre>

</section>
<section id="slide-sec-17-20">
<h3 id="sec-17-20">Filesystem</h3>
<ul>
<li>Usemos <code>ext4</code>.</li>
<li>Formatea con el siguiente comando (¡Cuidado fíjate en la partición!)
<ul>
<li><code>-m 0</code> reduce el espacio para <code>root</code> a 0% en lugar del 5%.</li>
<li><code>-O extent, sparse_super, flex_bg</code> Mejora la lectura secuencial
(<code>extent</code>), y mejora las opciones de espacio (<code>sparse_super</code>) al no
almacenar tantos superbloques y por último empaca juntos los
metadatos (<code>flex_bg</code>).</li>

</ul></li>

</ul>

<pre class="example">
mkfs -t ext4 -m 0 -O extent, sparse_super, flex_bg /dev/sdb1
</pre>


<ul>
<li>En el <code>/etc/fstab</code>, activa las opciones <code>noatime</code>, <code>noadirtime</code></li>

</ul>

<pre class="example">
...
/dev/sda1 /disk1  ext4 noatime, noadirtime 1 2
...
</pre>


</section>
<section id="slide-sec-17-21">
<h3 id="sec-17-21">Ejercicio: Armar un <i>cluster</i></h3>
<ul>
<li>El objetivo es reproducir el siguiente diagrama arquitectónico (por
lo menos).</li>

</ul>


<div class="figure">
<p><img src="./imagenes/layout.png" alt="layout.png" />
</p>
</div>


<ul>
<li>Use <code>Vagrant</code>, <code>chef</code> y <code>berkshelf</code>.</li>

</ul>


</section>
</section>
<section>
<section id="slide-sec-18">
<h2 id="sec-18">Compresores</h2>
<div class="outline-text-2" id="text-18">
</div></section>
<section id="slide-sec-18-1">
<h3 id="sec-18-1">Instalación</h3>
<pre class="example">
# Snappy
sudo apt-get install libsnappy1 libsnappy-dev

#LZO
sudo apt-get install liblzo2-2 liblzo2-dev#+end_example
</pre>

</section>
<section id="slide-sec-18-2">
<h3 id="sec-18-2">Tipos</h3>

<div class="figure">
<p><img src="./imagenes/compresores.png" alt="compresores.png" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-sec-19">
<h2 id="sec-19">Misceláneos</h2>
<div class="outline-text-2" id="text-19">
</div></section>
<section id="slide-sec-19-1">
<h3 id="sec-19-1">Tips</h3>
<ul>
<li><code>Reduce</code> es regularmente más intensivo en cuanto consumo de recursos que <code>Map</code>
<ul>
<li>Usa <code>Combiners</code>.</li>
<li>Explora tus datos antes
<ul>
<li>Como están distribuidos es muy importante.</li>
<li>Quizá Hadoop no sea lo correcto.</li>

</ul></li>

</ul></li>

<li>En la vida real, instala desde una distribución: <b>BigTop</b>, <b>Horton</b> o <b>Cloudera</b>.
<ul>
<li>Y <code>Vagrant</code></li>

</ul></li>

</ul>

</section>
<section id="slide-sec-19-2">
<h3 id="sec-19-2"><i>Small File Problem</i></h3>

</section>
</section>
<section>
<section id="slide-sec-20">
<h2 id="sec-20">Disclaimer</h2>
<p>
Algunas imágenes se tomaron de los libros <i>Professional Hadoop Solutions</i>
de <b>Wrox</b> y de la página de <a href="http://hortonworks.com/hadoop/yarn/">Hortonworks</a>. Las otras son mías.
</p>

<p>
Las tablas de la sección <i>cluster</i> de Hadoop, se tomaron de <a href="http://hortonworks.com/">Hortonworks.</a>
</p>
</section>
</section>
</div>
</div>
<p> Creado por Adolfo De Unánue Tiscareño. </p>

<script src="http://cdn.jsdelivr.net/reveal.js/2.5.0/lib/js/head.min.js"></script>
<script src="http://cdn.jsdelivr.net/reveal.js/2.5.0/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: true,
rollingLinks: true,
keyboard: true,
overview: true,
width: 1200,
height: 800,
margin: 0.10,
minScale: 0.50,
maxScale: 2.50,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'fade', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'default',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: 'http://cdn.jsdelivr.net/reveal.js/2.5.0/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
 { src: 'http://cdn.jsdelivr.net/reveal.js/2.5.0/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'http://cdn.jsdelivr.net/reveal.js/2.5.0/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'http://cdn.jsdelivr.net/reveal.js/2.5.0/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
]
});
</script>
</body>
</html>
